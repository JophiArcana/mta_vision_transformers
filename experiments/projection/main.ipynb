{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"/workspace/mta_vision_transformers/\")\n",
    "from collections import OrderedDict\n",
    "from typing import Any, Callable, Dict, Iterable, List, Set, Tuple\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import einops\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Fn\n",
    "import torch.utils.data\n",
    "from matplotlib import pyplot as plt\n",
    "from tensordict import TensorDict\n",
    "from torch.utils._pytree import tree_flatten\n",
    "\n",
    "from core.monitor import Monitor\n",
    "from infrastructure import utils\n",
    "from infrastructure.settings import DEVICE, OUTPUT_DEVICE, DTYPE\n",
    "from dataset.construct import ImageDataset\n",
    "from dataset.library import DATASETS\n",
    "\n",
    "\n",
    "dataset_name, n_classes = DATASETS[\"Common\"][1]\n",
    "OUTPUT_DIR = \"experiments/projection\"\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "# Ocean: 901085904\n",
    "# Rose: 100390212\n",
    "torch.set_printoptions(linewidth=400, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.evaluation import ImageTextDataset, run_retrieval_evaluation, print_retrieval_metrics, DEFAULT_DATASET\n",
    "from modeling.image_features import ImageFeatures\n",
    "from modeling.openclip_vit import OpenCLIPViT\n",
    "from modeling.vit_projection import OpenCLIPProjectionViT\n",
    "\n",
    "\n",
    "utils.reset_seed()\n",
    "# Run evaluation\n",
    "evaluation_kwargs: Dict[str, Any] = {\"subsample\": 5000, \"n_ev\": 1}\n",
    "\n",
    "# Evaluate base model\n",
    "print(\"=\" * 120)\n",
    "print(\"Base model\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "baseline_fname = f\"{OUTPUT_DIR}/metrics/baseline.pt\"\n",
    "if not os.path.exists(baseline_fname):\n",
    "    baseline_model = OpenCLIPViT().to(DEVICE)\n",
    "    baseline_metrics: TensorDict = run_retrieval_evaluation(baseline_model, **evaluation_kwargs)\n",
    "    torch.save(baseline_metrics, baseline_fname)\n",
    "else:\n",
    "    baseline_metrics: TensorDict = torch.load(baseline_fname, map_location=DEVICE)\n",
    "print_retrieval_metrics(baseline_metrics)\n",
    "print()\n",
    "\n",
    "# Evaluate compression model\n",
    "print(\"=\" * 120)\n",
    "print(\"Compression model\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "mode: OpenCLIPProjectionViT.ModeOptions = \"ReLU -> sum\"\n",
    "mask_type: OpenCLIPProjectionViT.MaskOptions = \"X -> X\"\n",
    "\n",
    "MA_mask: torch.Tensor = torch.load(f\"experiments/saved_masks/MA_mask.pt\", map_location=DEVICE, weights_only=True)\n",
    "AS_mask: torch.Tensor = torch.load(f\"experiments/saved_masks/AS_mask.pt\", map_location=DEVICE, weights_only=True)\n",
    "mask_dict: Dict[str, torch.Tensor] = {\n",
    "    \"all\": (torch.arange(ImageFeatures.N + 1) > 0).expand((len(DEFAULT_DATASET), ImageFeatures.N + 1)),\n",
    "    # \"normal\": (torch.arange(ImageFeatures.N + 1) > 0) * ~AS_mask,\n",
    "    # \"MA\": MA_mask,\n",
    "    # \"AS\": AS_mask,\n",
    "}\n",
    "\n",
    "lo, hi = 17, 17\n",
    "for k, mask in mask_dict.items():\n",
    "    print(f\"{k}:\")\n",
    "    compression_fname = f\"{OUTPUT_DIR}/metrics/({mode})_({mask_type})_{k}[{lo}:{hi}].pt\"\n",
    "    if not os.path.exists(compression_fname):\n",
    "        mask_layers: Iterable[int] = range(lo, hi)\n",
    "\n",
    "        dataset = copy.copy(DEFAULT_DATASET)\n",
    "        dataset.load_cache({\"mask\": mask})\n",
    "        compression_model = OpenCLIPProjectionViT({i: (mode, mask_type) for i in range(lo, hi)}).to(DEVICE)\n",
    "        compression_metrics: TensorDict = run_retrieval_evaluation(compression_model, dataset=dataset, **evaluation_kwargs)\n",
    "        torch.save(compression_metrics, compression_fname)\n",
    "    else:\n",
    "        compression_metrics: TensorDict = torch.load(compression_fname, map_location=DEVICE)\n",
    "    print_retrieval_metrics(compression_metrics)\n",
    "\n",
    "# result_grid = np.empty((ImageFeatures.NUM_LAYERS, ImageFeatures.NUM_LAYERS), dtype=object).tolist()\n",
    "# for lo in range(12, ImageFeatures.NUM_LAYERS):\n",
    "#     for hi in range(lo + 1, ImageFeatures.NUM_LAYERS + 1):\n",
    "#         compression_fname = f\"{OUTPUT_DIR}/metrics/remove_normal[{lo}:{hi}].pt\"\n",
    "#         if not os.path.exists(compression_fname):\n",
    "#             mask_layers: Iterable[int] = range(lo, hi)\n",
    "\n",
    "#             AS_mask: torch.Tensor = torch.load(f\"experiments/saved_masks/AS_mask.pt\", map_location=DEVICE)\n",
    "#             normal_mask: torch.Tensor = (torch.arange(ImageFeatures.N + 1) > 0) * ~AS_mask\n",
    "\n",
    "#             dataset = copy.copy(DEFAULT_DATASET)\n",
    "#             dataset.load_cache({\"mask\": normal_mask})\n",
    "#             compression_model = OpenCLIPAttentionViT(mode, mask_type, mask_layers).to(DEVICE)\n",
    "#             compression_metrics: TensorDict = run_retrieval_evaluation(compression_model, dataset=dataset, **evaluation_kwargs)\n",
    "#             torch.save(compression_metrics, compression_fname)\n",
    "#         else:\n",
    "#             compression_metrics: TensorDict = torch.load(compression_fname, map_location=DEVICE)\n",
    "        \n",
    "#         result_grid[lo, hi] = compression_metrics\n",
    "#         print_retrieval_metrics(compression_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
